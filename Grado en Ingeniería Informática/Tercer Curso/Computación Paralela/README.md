# ‚ö° Computaci√≥n Paralela

## üìå Introducci√≥n
La asignatura estudia la **ejecuci√≥n simult√°nea de operaciones** en m√∫ltiples unidades de procesamiento.  
Se analizan los **l√≠mites f√≠sicos y algor√≠tmicos del paralelismo**, as√≠ como tres grandes modelos de programaci√≥n: **OpenMP, MPI y CUDA**.

---

## üîπ Contenidos principales

### üß† Fundamentos
- Clasificaci√≥n de arquitecturas: SISD, SIMD, MISD, MIMD.  
- Modelos de memoria: compartida, distribuida e h√≠brida.  
- Paralelismo de **datos** y **tareas**.  
- Speedup, escalabilidad y leyes del paralelismo (Amdahl, Gustafson).  

---

### üßµ OpenMP (memoria compartida)
- API para C, C++ y Fortran mediante directivas.  
- Regiones paralelas, bucles paralelizados y secciones independientes.  
- Control de hilos y planificaci√≥n del trabajo.  
- Variables compartidas y privadas.  
- Mecanismos de reducci√≥n.  
- Estrategias de planificaci√≥n y sincronizaci√≥n.  

---

### üåç MPI (memoria distribuida)
- Biblioteca est√°ndar para **paso de mensajes** en sistemas distribuidos.  
- Cada proceso usa su propia memoria local y se comunica mediante mensajes.  
- Inicializaci√≥n y finalizaci√≥n del entorno MPI.  
- Identificaci√≥n y organizaci√≥n de procesos mediante grupos y comunicadores.  
- Env√≠o, recepci√≥n y sincronizaci√≥n de mensajes.  
- Comunicaciones colectivas (broadcast, gather, scatter, reduce).  
- Modelo de ejecuci√≥n **SPMD (Single Program, Multiple Data)**.  

---

### üéÆ CUDA (GPU ‚Äì GPGPU)
- Plataforma de **NVIDIA** para c√≥mputo paralelo en GPUs.  
- Modelo jer√°rquico de ejecuci√≥n: grids, bloques e hilos.  
- Identificadores de hilos y bloques para organizar el paralelismo.  
- Jerarqu√≠a de memoria: global, compartida, registros y cach√©s.  
- Sincronizaci√≥n de hilos dentro de un bloque.  
- Gesti√≥n de memoria y transferencia entre CPU y GPU.  
- Optimizaci√≥n de kernels para maximizar el rendimiento.  

---

## üéØ Objetivos de la asignatura
- Comprender los fundamentos del paralelismo y sus limitaciones.  
- Conocer los principales modelos de programaci√≥n paralela.  
- Aprender a dise√±ar algoritmos paralelos eficientes.  
- Aplicar t√©cnicas con OpenMP, MPI y CUDA en la pr√°ctica.  
